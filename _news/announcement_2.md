---
layout: post
title: Presentation at DGM4MICCAI workshop
date: 2023-10-08 07:00:00-0400
inline: false
related_posts: false
---

Abstract:

The use of deep generative models for unsupervised anomaly
detection is an area of research that has gained interest in recent years in
the field of medical imaging. Among all the existing models, the variational
autoencoder (VAE) has proven to be efficient while remaining simple to
use. Much research to improve the original method has been achieved in
the computer vision literature, but rarely translated to medical imaging
applications. To fill this gap, we propose a benchmark of fifteen variants
of VAE that we compare with a vanilla autoencoder and VAE for a
neuroimaging use case relying on a simulation-based evaluation framework.
The use case is the detection of anomalies related to Alzheimerâ€™s disease
and other dementias in 3D FDG PET.

We show that among the fifteen VAE variants tested, nine lead to a good
reconstruction accuracy and are able to generate healthy-looking images.
This indicates that many approaches developed for computer vision
applications can generalize to the unsupervised detection of anomalies
of various shapes, intensities and locations in 3D FDG PET. However,
these models do not outperform the vanilla autoencoder and VAE.

Paper Link : https://hal.science/hal-04185304/file/DGM4MICCAI_Hassanaly.pdf